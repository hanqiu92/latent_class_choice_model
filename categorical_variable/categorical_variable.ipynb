{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "JLpLa8Jt7Vu4"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.optimize as opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f_raw = open('quebec.dat','rb')\n",
    "sample_size = 3090\n",
    "cate_list = [0,3,4,5,8]\n",
    "cate_name = ['sector','conv_year','house_type','constr_year','own_rent']\n",
    "cate_data = np.ndarray(shape=(sample_size,len(cate_list)),dtype=np.int64)\n",
    "shared_list = [1,6,7,9,10,11]\n",
    "shared_data = np.ndarray(shape=(sample_size,len(shared_list)),dtype=np.float64)\n",
    "num_labels = 9\n",
    "num_individual = 4\n",
    "individual_data = np.ndarray(shape=(num_labels,sample_size,num_individual),dtype=np.float64)\n",
    "label_i = np.ndarray(shape=(sample_size),dtype=np.int64)\n",
    "label = np.zeros(shape=(num_labels,sample_size),dtype=np.float64)\n",
    "count = 0\n",
    "\n",
    "for line in f_raw:\n",
    "    if count > 0:\n",
    "        data = line.strip().split(\"\\t\")\n",
    "        # sector, hdd, choice, conv_year, house_type, constr_year, nb_rooms, nb_pers,\n",
    "        #    own_rent, surface, age, income = data[:12]\n",
    "        # op_cost = data[12:21]\n",
    "        # fix_cost = data[21:30]\n",
    "        # cost_inc = data[30:39]\n",
    "        # avail = data[39:48]   \n",
    "        for i in xrange(len(cate_list)):\n",
    "            cate_data[count-1,i] = int(data[cate_list[i]])\n",
    "        for i in xrange(len(shared_list)):\n",
    "            shared_data[count-1,i] = float(data[shared_list[i]])\n",
    "        for i in xrange(num_individual):\n",
    "            for j in xrange(num_labels):\n",
    "                individual_data[j,count-1,i] = float(data[12+i*num_labels+j])\n",
    "        label_i[count-1] = int(data[2])-1\n",
    "        label[int(data[2])-1,count-1] = 1.0\n",
    "    count += 1\n",
    "    \n",
    "f_raw.close()\n",
    "\n",
    "num_vari = len(shared_list)+num_individual+1\n",
    "numer_data = np.ones(shape=(num_labels,sample_size,num_vari),dtype=np.float64)\n",
    "numer_data[:,:,(len(shared_list)+1):] = individual_data\n",
    "for i in xrange(num_labels):\n",
    "    numer_data[i,:,1:(len(shared_list)+1)] = shared_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def likelihood(w, data, label):\n",
    "    num_labels, sample_size, num_vari = data.shape\n",
    "    util = np.zeros((num_labels,sample_size),np.float64)\n",
    "    for i in xrange(num_labels):\n",
    "        util[i,:] = np.dot(data[i,:,:],w[i*num_vari:(i+1)*num_vari])\n",
    "    util = np.exp(util - util.max(axis=0))\n",
    "    prob = util / util.sum(axis=0)\n",
    "    prob = np.sum(prob * label,axis=0)\n",
    "    out = np.sum(-np.log(prob))\n",
    "    return out\n",
    "\n",
    "def l_gradient(w, data, label):\n",
    "    num_labels, sample_size, num_vari = data.shape\n",
    "    out = np.zeros((num_labels,num_vari),np.float64)\n",
    "    util = np.zeros((num_labels,sample_size),np.float64)\n",
    "    for i in xrange(num_labels):\n",
    "        util[i,:] = np.dot(data[i,:,:],w[i*num_vari:(i+1)*num_vari])\n",
    "    util = np.exp(util - util.max(axis=0))\n",
    "    prob = util / util.sum(axis=0)\n",
    "    for i in xrange(num_labels):\n",
    "        out[i,:] = np.sum(data[i,:,:].T * (prob[i,:] - label[i,:]),axis=1)\n",
    "    out = np.reshape(out,(num_vari*num_labels))\n",
    "    if np.dot(out,out) > 1e-8:\n",
    "        out = out / np.sqrt(np.dot(out,out))\n",
    "    return out\n",
    "\n",
    "def p_gradient(w, data, label, epsilon):\n",
    "    num_labels, sample_size, num_vari = data.shape\n",
    "    grad_temp = np.zeros((sample_size,num_labels,num_vari),np.float64)\n",
    "    out = np.ndarray(shape=(sample_size,num_labels*num_vari),dtype=np.float64)\n",
    "    util = np.zeros((num_labels,sample_size),np.float64)\n",
    "    for i in range(num_labels):\n",
    "        util[i,:] = np.dot(data[i,:,:],w[i*num_vari:(i+1)*num_vari])\n",
    "    util = np.exp(util - util.max(axis=0))\n",
    "    prob = util / util.sum(axis=0)\n",
    "    for i in xrange(num_labels):\n",
    "        grad_temp[:,i,:] = (data[i,:,:].T * (prob[i,:] - label[i,:])).T\n",
    "    for n in xrange(sample_size):   \n",
    "        grad = np.reshape(grad_temp[n,:,:],(num_vari*num_labels))\n",
    "        if np.dot(grad,grad) > 1e-8:\n",
    "            grad = grad / np.sqrt(np.dot(grad,grad))\n",
    "        out[n,:] = grad\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial:  6789.42394397\n",
      "iteration  0 :\n",
      "class  0  loss: 1361.97543072\n",
      "total loss: 1361.97543072\n",
      "iteration  0 : category= constr_year , boundary value= 7\n",
      "iteration  1 :\n",
      "class  0  loss: 560.960256356\n",
      "class  1  loss: 498.664979062\n",
      "total loss: 1059.62523542\n"
     ]
    }
   ],
   "source": [
    "weight_init = np.zeros(num_vari*num_labels,np.float64)\n",
    "loss = likelihood(weight_init, numer_data, label)\n",
    "delta_loss = loss\n",
    "print 'initial: ',loss\n",
    "delta_bound = delta_loss * 1e-3\n",
    "epsilon = 1.0 / np.sqrt(sample_size) * 1e0\n",
    "class_size = 1\n",
    "class_max = 10\n",
    "data_list = [numer_data]\n",
    "weight_list = [weight_init]\n",
    "label_list = [label]\n",
    "category_list = [cate_data]\n",
    "iter_count = 0\n",
    "\n",
    "while (delta_loss > delta_bound) and (class_size < class_max):\n",
    "    # first step: calculate MLE for each class\n",
    "    loss_old = loss\n",
    "    loss = 0\n",
    "    print 'iteration ',iter_count,':'\n",
    "    for i in xrange(class_size):\n",
    "        res = opt.minimize(likelihood,weight_list[i],jac = l_gradient,\n",
    "                                       args = (data_list[i],label_list[i]))\n",
    "        weight_list[i] = res.x\n",
    "        temp_loss = likelihood(weight_list[i],data_list[i],label_list[i])\n",
    "        loss += temp_loss\n",
    "        print 'class ',i,' loss:',temp_loss\n",
    "    print 'total loss:',loss\n",
    "    delta_loss = loss_old - loss\n",
    "    \n",
    "    # second step: calculate pointwise gradient (transformed)\n",
    "    # third step: classification with categorical data\n",
    "    max_i = -1\n",
    "    max_rate = 0\n",
    "    for i in xrange(class_size):\n",
    "        category_label = p_gradient(weight_list[i],data_list[i],label_list[i],epsilon)\n",
    "        category_data = category_list[i]\n",
    "        category_variable_size = category_data.shape[1]\n",
    "        # cate_data with shape (n,m_c); cate_label with shape (n,m_w)\n",
    "        max_v = np.sum(np.abs(np.sum(category_label,axis=0)))\n",
    "        max_c = -1\n",
    "        max_t = -1\n",
    "        for c in xrange(category_variable_size):\n",
    "            type_set = np.unique(category_data[:,c])\n",
    "            for t in type_set:\n",
    "                v = 0\n",
    "                v += np.sum(np.abs(np.sum(category_label[category_data[:,c]<=t,:],axis=0)))\n",
    "                v += np.sum(np.abs(np.sum(category_label[category_data[:,c]>t,:],axis=0)))\n",
    "                if v > max_v:\n",
    "                    max_v = v\n",
    "                    max_c = c\n",
    "                    max_t = t\n",
    "        \n",
    "        rate = float(max_v) - float(np.sum(np.abs(np.sum(category_label,axis=0))))\n",
    "        if rate > max_rate:\n",
    "            max_rate = rate\n",
    "            max_i = i\n",
    "    \n",
    "    if max_i >= 0:\n",
    "        category_data = category_list[max_i]\n",
    "        ind_1 = category_data[:,max_c]<=max_t\n",
    "        ind_2 = category_data[:,max_c]>max_t\n",
    "        if (np.sum(ind_1)>0) and (np.sum(ind_2)>0):\n",
    "            class_size += 1\n",
    "            \n",
    "            data_temp = data_list[max_i]\n",
    "            data_list.append(data_temp[:,ind_1,:])\n",
    "            data_list.append(data_temp[:,ind_2,:])\n",
    "            del data_list[max_i]\n",
    "            del data_temp\n",
    "            \n",
    "            weight_list.append(weight_list[max_i])\n",
    "            weight_list.append(weight_list[max_i])\n",
    "            del weight_list[max_i]\n",
    "            \n",
    "            label_temp = label_list[max_i]\n",
    "            label_list.append(label_temp[:,ind_1])\n",
    "            label_list.append(label_temp[:,ind_2])\n",
    "            del label_list[max_i]\n",
    "            del label_temp\n",
    "            \n",
    "            category_temp = category_list[max_i]\n",
    "            category_list.append(category_temp[ind_1,:])\n",
    "            category_list.append(category_temp[ind_2,:])\n",
    "            del category_list[max_i]\n",
    "            del category_temp\n",
    "            \n",
    "            print 'iteration ',iter_count,': category=',cate_name[max_c],', boundary value=',max_t\n",
    "        else:\n",
    "            delta_loss = 0\n",
    "    else:\n",
    "        delta_loss = 0\n",
    "    \n",
    "    iter_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "name": "2_fullyconnected.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
